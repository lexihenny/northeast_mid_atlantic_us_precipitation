{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'\n",
    "\n",
    "#Finds dates associated with each weather type and plots composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(dir+'extreme_days_ghcnd_99station_80area95.nc')\n",
    "lats=ds['lats'].values.tolist()\n",
    "lons=ds['lons'].values.tolist()\n",
    "lons=[x+360. for x in lons]\n",
    "dates=ds['dates'].values\n",
    "dates_unique=list(set(dates))\n",
    "dates_unique=pd.DatetimeIndex(dates_unique).sort_values()\n",
    "stations=ds['stations'].values.tolist()\n",
    "obs=ds['obs'].values.tolist()\n",
    "print(dates)\n",
    "\n",
    "ds1=xr.open_dataset(dir+'ivt_basics_neusa.nc')\n",
    "ivt_threshold=ds1['ivt_threshold']\n",
    "ivt_mag=ds1['ivt_mag']\n",
    "ivtx=ds1['ivtx']\n",
    "ivty=ds1['ivty']\n",
    "print(ivtx.time)\n",
    "\n",
    "lon_range=np.arange(-125,-30,0.25)\n",
    "lat_range=np.arange(15,60,0.25)\n",
    "if 1==1:\n",
    "    ds3=xr.open_dataset(dir+'era_5_fall_u_850_neusa.nc')\n",
    "    u_850=ds3['u'].sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds8=xr.open_dataset(dir+'era_5_fall_v_850_neusa.nc')\n",
    "    v_850=ds8['v'].sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds5=xr.open_dataset(dir+'era_5_fall_mslp_neusa.nc')\n",
    "    print(ds5)\n",
    "    slp=ds5['msl'].sel(latitude=lat_range,longitude=lon_range)\n",
    "\n",
    "    ds6=xr.open_dataset(dir+'era_5_fall_sfc_remnants_neusa.nc')\n",
    "    print(ds6)\n",
    "    ds6['longitude']=ds6.longitude.values-180\n",
    "    slp_2=ds6['mslp'].sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds7=xr.open_dataset(dir+'era_5_fall_pl_remnants_neusa.nc')\n",
    "    ds7['longitude']=ds7.longitude.values-180\n",
    "    u_850_2=ds7['u'].sel(latitude=lat_range,longitude=lon_range)\n",
    "    v_850_2=ds7['v'].sel(latitude=lat_range,longitude=lon_range)\n",
    "\n",
    "ds4=xr.open_dataset(dir+'neusa_ep_days_stats_var95const_station95.nc')\n",
    "ar_yesno4=ds4['ar_yesno'].values.tolist()\n",
    "ivt_yesno4=ds4['ivt_yesno'].values.tolist()\n",
    "tc_yesno4=ds4['tc_yesno'].values.tolist()\n",
    "other_yesno4=ds4['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno4=ds4['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno4=ds4['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno4=ds4['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno4=ds4['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno4=ds4['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno4=ds4['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno4=ds4['tc_ar_combo_yesno'].values.tolist()\n",
    "print(sum(ar_yesno4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_t1=list(zip(dates_unique,ar_yesno4))#ar-related = green\n",
    "zipped_t2=list(zip(dates_unique,tc_linked_ar_yesno4))\n",
    "zipped_t3=list(zip(dates_unique,tc_remnant_linked_ar_yesno4))\n",
    "zipped_t4=list(zip(dates_unique,tc_yesno4))#tc-related = blue\n",
    "zipped_t5=list(zip(dates_unique,tc_ar_combo_yesno4))\n",
    "zipped_t6=list(zip(dates_unique,tc_remnant_ar_combo_yesno4))\n",
    "zipped_t7=list(zip(dates_unique,tc_remnants_yesno4))\n",
    "zipped_t8=list(zip(dates_unique,ivt_yesno4))#other IVT-related = grey\n",
    "zipped_t9=list(zip(dates_unique,tc_linked_ivt_yesno4))\n",
    "zipped_t10=list(zip(dates_unique,tc_remnant_linked_ivt_yesno4))\n",
    "zipped_t11=list(zip(dates_unique,other_yesno4))#unspecified = brown\n",
    "\n",
    "dates_t1=[x[0] for x in zipped_t1 if x[1]==1]\n",
    "dates_t2=[x[0] for x in zipped_t2 if x[1]==1]\n",
    "dates_t3=[x[0] for x in zipped_t3 if x[1]==1]\n",
    "dates_t4=[x[0] for x in zipped_t4 if x[1]==1]\n",
    "dates_t5=[x[0] for x in zipped_t5 if x[1]==1]\n",
    "dates_t6=[x[0] for x in zipped_t6 if x[1]==1]\n",
    "dates_t7=[x[0] for x in zipped_t7 if x[1]==1]\n",
    "dates_t8=[x[0] for x in zipped_t8 if x[1]==1]\n",
    "dates_t9=[x[0] for x in zipped_t9 if x[1]==1]\n",
    "dates_t10=[x[0] for x in zipped_t10 if x[1]==1]\n",
    "dates_t11=[x[0] for x in zipped_t11 if x[1]==1]\n",
    "\n",
    "dates_t1=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t1]\n",
    "dates_t2=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t2]\n",
    "dates_t3=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t3]\n",
    "dates_t4=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t4]\n",
    "dates_t5=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t5]\n",
    "dates_t6=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t6]\n",
    "dates_t7=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t7]\n",
    "dates_t8=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t8]\n",
    "dates_t9=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t9]\n",
    "dates_t10=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t10]\n",
    "dates_t11=[pd.to_datetime(x)+dt.timedelta(hours=12) for x in dates_t11]\n",
    "\n",
    "dates_ar=dates_t1+dates_t2+dates_t3\n",
    "dates_tc=dates_t4+dates_t5+dates_t6+dates_t7\n",
    "dates_other=dates_t8+dates_t9+dates_t10+dates_t11\n",
    "\n",
    "dates_tc=pd.DatetimeIndex(dates_tc)\n",
    "dates_tc_first=[x for x in dates_tc if x.year<=1999]\n",
    "dates_tc_second=[x for x in dates_tc if x.year>=2000]\n",
    "print(dates_tc_first)\n",
    "\n",
    "dates_unique_first=[x for x in dates_unique if x.year<=1999]\n",
    "dates_unique_second=[x for x in dates_unique if x.year>=2000]\n",
    "\n",
    "dates_ar=pd.DatetimeIndex(dates_ar)\n",
    "dates_ar_first=[x for x in dates_ar if x.year<=1999]\n",
    "dates_ar_second=[x for x in dates_ar if x.year>=2000]\n",
    "\n",
    "print(dates_t1)\n",
    "print(dates_t2)\n",
    "print(dates_t3)\n",
    "print(dates_t4)\n",
    "print(dates_t5)\n",
    "print(dates_t6)\n",
    "print(dates_t7)\n",
    "print(dates_t8)\n",
    "print(dates_t9)\n",
    "print(dates_t10)\n",
    "print(dates_t11)\n",
    "\n",
    "print(dates_tc)\n",
    "print(dates_ar)\n",
    "print(dates_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivt_mag_sel=ivt_mag.sel(time=dates_t4)\n",
    "u_850_sel=u_850.sel(time=dates_t4)\n",
    "v_850_sel=v_850.sel(time=dates_t4)\n",
    "slp_sel=slp.sel(time=dates_t4)\n",
    "ivt_mean=ivt_mag_sel.mean(dim='time',skipna=True)\n",
    "u_mean=u_850_sel.mean(dim='time',skipna=True)\n",
    "v_mean=v_850_sel.mean(dim='time',skipna=True)\n",
    "slp_mean=slp_sel.mean(dim='time',skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to draw grid lines on Lambert Conformal projection; \n",
    "#CREDIT ajdawson on GitHub https://gist.github.com/ajdawson/dd536f786741e987ae4e\n",
    "\n",
    "from copy import copy\n",
    "import shapely.geometry as sgeom\n",
    "def find_side(ls, side):\n",
    "    \"\"\"\n",
    "    Given a shapely LineString which is assumed to be rectangular, return the\n",
    "    line corresponding to a given side of the rectangle.\n",
    "    \n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = ls.bounds\n",
    "    points = {'left': [(minx, miny), (minx, maxy)],\n",
    "              'right': [(maxx, miny), (maxx, maxy)],\n",
    "              'bottom': [(minx, miny), (maxx, miny)],\n",
    "              'top': [(minx, maxy), (maxx, maxy)],}\n",
    "    return sgeom.LineString(points[side])\n",
    "\n",
    "\n",
    "def lambert_xticks(ax, ticks):\n",
    "    \"\"\"Draw ticks on the bottom x-axis of a Lambert Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[0]\n",
    "    lc = lambda t, n, b: np.vstack((np.zeros(n) + t, np.linspace(b[2], b[3], n))).T\n",
    "    xticks, xticklabels = _lambert_ticks(ax, ticks, 'bottom', lc, te)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([ax.xaxis.get_major_formatter()(xtick) for xtick in xticklabels])\n",
    "    \n",
    "\n",
    "def lambert_yticks(ax, ticks):\n",
    "    \"\"\"Draw ricks on the left y-axis of a Lamber Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[1]\n",
    "    lc = lambda t, n, b: np.vstack((np.linspace(b[0], b[1], n), np.zeros(n) + t)).T\n",
    "    yticks, yticklabels = _lambert_ticks(ax, ticks, 'left', lc, te)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([ax.yaxis.get_major_formatter()(ytick) for ytick in yticklabels])\n",
    "def _lambert_ticks(ax, ticks, tick_location, line_constructor, tick_extractor):\n",
    "    \"\"\"Get the tick locations and labels for an axis of a Lambert Conformal projection.\"\"\"\n",
    "    outline_patch = sgeom.LineString(ax.outline_patch.get_path().vertices.tolist())\n",
    "    axis = find_side(outline_patch, tick_location)\n",
    "    n_steps = 30\n",
    "    extent = ax.get_extent(ccrs.PlateCarree())\n",
    "    _ticks = []\n",
    "    for t in ticks:\n",
    "        xy = line_constructor(t, n_steps, extent)\n",
    "        proj_xyz = ax.projection.transform_points(ccrs.Geodetic(), xy[:, 0], xy[:, 1])\n",
    "        xyt = proj_xyz[..., :2]\n",
    "        ls = sgeom.LineString(xyt.tolist())\n",
    "        locs = axis.intersection(ls)\n",
    "        if not locs:\n",
    "            tick = [None]\n",
    "        else:\n",
    "            tick = tick_extractor(locs.xy)\n",
    "        _ticks.append(tick[0])\n",
    "    # Remove ticks that aren't visible:    \n",
    "    ticklabels = copy(ticks)\n",
    "    while True:\n",
    "        try:\n",
    "            index = _ticks.index(None)\n",
    "        except ValueError:\n",
    "            break\n",
    "        _ticks.pop(index)\n",
    "        ticklabels.pop(index)\n",
    "    return _ticks, ticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsa=xr.open_dataset(dir+'neusa_ar_climo_fall.nc')\n",
    "ar=dsa.ar\n",
    "tc_trop=dsa.tc_trop\n",
    "tc_nontrop=dsa.tc_nontrop\n",
    "labeled=dsa.labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_sel=ar.sel(time=dates_t4).fillna(0)\n",
    "ar_mean=ar_sel.mean(dim='time',skipna=True)\n",
    "ar_mean=ar_mean.where(ar_mean>=0.4)\n",
    "ar_mean=ar_mean/ar_mean\n",
    "ar_mean['longitude']=ar_mean.longitude.values-360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "month_dict={'1':'January','2':'February','3':'March','4':'April','5':'May','6':'June','7':'July','8':'August','9':'September','10':'October','11':'November','12':'December'}    \n",
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(24,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-100,-45,15,55],crs=ccrs.PlateCarree())\n",
    "\n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-135,-130,-125,-120,-115,-110,-105,-95,-85,-75,-65,-55,-45,-40,-35,-30,-25,-20]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=24)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "\n",
    "cax1=ax.contourf(ivt_mean.longitude,ivt_mean.latitude,ivt_mean,levels=np.arange(250,800,40),extend='both',transform=ccrs.PlateCarree(),cmap=plt.cm.Greys,alpha=0.5)\n",
    "cbar=plt.colorbar(cax1,pad=0,fraction=0.046)\n",
    "cbar.set_label('kg/m/s',fontsize=26,rotation=90,labelpad=15)\n",
    "cbar.ax.tick_params(labelsize=24)\n",
    "\n",
    "c=ax.contour(slp_mean.longitude,slp_mean.latitude,slp_mean/100.,transform=ccrs.PlateCarree(),colors='k',levels=np.arange(960,1040,4))\n",
    "plt.clabel(c,fmt='%.00f',fontsize=19)\n",
    "X=8\n",
    "q=ax.quiver(u_mean.longitude[0::X].values,u_mean.latitude[0::X].values,u_mean[0::X,0::X].values,v_mean[0::X,0::X].values,transform=ccrs.PlateCarree(),units='inches',scale=20,width=0.045,alpha=0.5)\n",
    "ax.quiverkey(q,0.94,1.01,10,'10 m/s',fontproperties={'size':18})\n",
    "ax.set_title('Pure TC',fontsize=44,pad=10)\n",
    "\n",
    "cax2=ax.contourf(ar_mean.longitude,ar_mean.latitude,ar_mean,[0,1],colors='b',transform=ccrs.PlateCarree(),hatches=[None,'.'],alpha=0.1,label='AR probability >= 0.5',zorder=20)    \n",
    "mpl.rcParams['hatch.linewidth']=0.01\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "ax.text(0.01, 0.9875,'n='+str(len(dates_t4)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props,zorder=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'neusa_wtype_95composite_111.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-bryan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
