{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import scipy.stats as st\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'\n",
    "#look at ER trends from all different weather types (and sums of weather type categories) geographically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-terrace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ds=xr.open_dataset(dir+'extreme_days_ghcnd.nc')\n",
    "ds=xr.open_dataset(dir+'extreme_days_ghcnd_99station_80area95.nc')\n",
    "lats=ds['lats'].values.tolist()\n",
    "lons=ds['lons'].values.tolist()\n",
    "lons=[x+360. for x in lons]\n",
    "dates=ds['dates'].values\n",
    "print(len(dates))\n",
    "\n",
    "dates_unique=list(set(dates))\n",
    "dates_unique=pd.DatetimeIndex(dates_unique).sort_values()\n",
    "stations=ds['stations'].values.tolist()\n",
    "obs=ds['obs'].values.tolist()\n",
    "print(dates)\n",
    "years=[x.year for x in dates_unique]\n",
    "print(years)\n",
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "\n",
    "ds4=xr.open_dataset(dir+'neusa_ep_days_stats_var95const_station95.nc')\n",
    "ar_yesno4=ds4['ar_yesno'].values.tolist()\n",
    "print(len(ar_yesno4))\n",
    "ivt_yesno4=ds4['ivt_yesno'].values.tolist()\n",
    "tc_yesno4=ds4['tc_yesno'].values.tolist()\n",
    "other_yesno4=ds4['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno4=ds4['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno4=ds4['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno4=ds4['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno4=ds4['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno4=ds4['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno4=ds4['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno4=ds4['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "#prior TC influences days\n",
    "dates_remote_tc_inf=[dt.datetime(1979,9,21,6),dt.datetime(1987,9,9,6),dt.datetime(1989,9,19,6),\n",
    "                     dt.datetime(1996,9,15,6),dt.datetime(2002,9,16,6),\n",
    "                     dt.datetime(2002,9,28,6),dt.datetime(2003,9,2,6),dt.datetime(2003,9,4,6),\n",
    "                     dt.datetime(2005,9,1,6),dt.datetime(2005,10,7,6),dt.datetime(2005,10,8,6),\n",
    "                     dt.datetime(2005,10,9,6),dt.datetime(2005,10,15,6),dt.datetime(2009,11,12,6),\n",
    "                     dt.datetime(2010,10,1,6),dt.datetime(2011,9,7,6),dt.datetime(2011,9,8,6),\n",
    "                     dt.datetime(2015,9,30,6),dt.datetime(2015,10,1,6),dt.datetime(2017,10,29,6),\n",
    "                     dt.datetime(2017,10,30,6),dt.datetime(2018,9,9,6),dt.datetime(2018,9,10,6),\n",
    "                     dt.datetime(2018,9,19,6)]\n",
    "print(len(dates_remote_tc_inf))\n",
    "remote_tc_inf_yesno4=[]\n",
    "for i in range(len(dates_unique)):\n",
    "    if dates_unique[i] in dates_remote_tc_inf:\n",
    "        remote_tc_inf_yesno4.append(1)\n",
    "    else:\n",
    "        remote_tc_inf_yesno4.append(0)\n",
    "print(sum(remote_tc_inf_yesno4))\n",
    "\n",
    "ds1=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "lats1=ds1['lats']#use these lists for plotting\n",
    "lons1=ds1['lons']\n",
    "stations1=ds1['stations']\n",
    "thresholds=ds1['thresholds_annual_99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_t1=list(zip(dates_unique,ar_yesno4))#ar-related = green\n",
    "zipped_t2=list(zip(dates_unique,tc_linked_ar_yesno4))\n",
    "zipped_t3=list(zip(dates_unique,tc_remnant_linked_ar_yesno4))\n",
    "zipped_t4=list(zip(dates_unique,tc_yesno4))#tc-related = blue\n",
    "zipped_t5=list(zip(dates_unique,tc_ar_combo_yesno4))\n",
    "zipped_t6=list(zip(dates_unique,tc_remnant_ar_combo_yesno4))\n",
    "zipped_t7=list(zip(dates_unique,tc_remnants_yesno4))\n",
    "zipped_t8=list(zip(dates_unique,ivt_yesno4))#other IVT-related = grey\n",
    "zipped_t9=list(zip(dates_unique,tc_linked_ivt_yesno4))\n",
    "zipped_t10=list(zip(dates_unique,tc_remnant_linked_ivt_yesno4))\n",
    "zipped_t11=list(zip(dates_unique,other_yesno4))#unspecified = brown\n",
    "\n",
    "zipped_t12=list(zip(dates_unique,remote_tc_inf_yesno4))#unspecified = brown\n",
    "\n",
    "dates_t1=[x[0] for x in zipped_t1 if x[1]==1]\n",
    "dates_t2=[x[0] for x in zipped_t2 if x[1]==1]\n",
    "dates_t3=[x[0] for x in zipped_t3 if x[1]==1]\n",
    "dates_t4=[x[0] for x in zipped_t4 if x[1]==1]\n",
    "dates_t5=[x[0] for x in zipped_t5 if x[1]==1]\n",
    "dates_t6=[x[0] for x in zipped_t6 if x[1]==1]\n",
    "dates_t7=[x[0] for x in zipped_t7 if x[1]==1]\n",
    "dates_t8=[x[0] for x in zipped_t8 if x[1]==1]\n",
    "dates_t9=[x[0] for x in zipped_t9 if x[1]==1]\n",
    "dates_t10=[x[0] for x in zipped_t10 if x[1]==1]\n",
    "dates_t11=[x[0] for x in zipped_t11 if x[1]==1]\n",
    "\n",
    "dates_t12=[x[0] for x in zipped_t12 if x[1]==1]\n",
    "\n",
    "dates_ar=dates_t1+dates_t2+dates_t3\n",
    "dates_tc=dates_t4+dates_t5+dates_t6+dates_t7\n",
    "dates_other=dates_t8+dates_t9+dates_t10+dates_t11\n",
    "\n",
    "dates_tc_inf=[]\n",
    "dates_no_tc_inf=[]\n",
    "dates_tc_inf=dates_tc+dates_t2+dates_t3+dates_t12+dates_t9+dates_t10\n",
    "dates_no_tc_inf=[x for x in dates_unique if x not in dates_tc_inf]\n",
    "dates_tc_complex_inf=dates_t5+dates_t6+dates_t7+dates_t2+dates_t3+dates_t12+dates_t9+dates_t10\n",
    "\n",
    "import collections\n",
    "print([item for item, count in collections.Counter(dates_tc_inf).items() if count > 1])\n",
    "\n",
    "dates_tc_inf=list(set(dates_tc_inf))\n",
    "dates_tc_inf=pd.DatetimeIndex(dates_tc_inf).sort_values()\n",
    "\n",
    "dates_no_tc_inf=list(set(dates_no_tc_inf))\n",
    "dates_no_tc_inf=pd.DatetimeIndex(dates_no_tc_inf).sort_values()\n",
    "\n",
    "dates_tc_complex_inf=list(set(dates_tc_complex_inf))\n",
    "dates_tc_complex_inf=pd.DatetimeIndex(dates_tc_complex_inf).sort_values()\n",
    "\n",
    "print(len(dates_tc_inf))\n",
    "print(len(dates_no_tc_inf))\n",
    "print(len(dates_tc_complex_inf))\n",
    "\n",
    "print(dates_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a71a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipped=list(zip(dates,stations,lats,lons,obs))\n",
    "zipped_stations=list(zip(stations1,lats1,lons1,thresholds))\n",
    "\n",
    "mean_obs_list_tc_inf=[]\n",
    "mean_obs_list_tc_complex_inf=[]\n",
    "mean_obs_list_no_tc_inf=[]\n",
    "for i in range(len(stations1)):\n",
    "    print(i)\n",
    "    station=stations1[i].values\n",
    "    \n",
    "    select_station_tc_inf=[x for x in zipped if x[1]==station and x[0] in dates_tc_inf]\n",
    "    select_station_tc_complex_inf=[x for x in zipped if x[1]==station and x[0] in dates_tc_complex_inf]\n",
    "    select_station_no_tc_inf=[x for x in zipped if x[1]==station and x[0] in dates_no_tc_inf]\n",
    "    \n",
    "    obs_station_tc_inf=[x[4] for x in select_station_tc_inf]\n",
    "    obs_station_tc_complex_inf=[x[4] for x in select_station_tc_complex_inf]\n",
    "    obs_station_no_tc_inf=[x[4] for x in select_station_no_tc_inf]\n",
    "    \n",
    "    mean_obs_station_tc_inf=float(sum(obs_station_tc_inf))/float(len(obs_station_tc_inf))\n",
    "    mean_obs_station_tc_complex_inf=float(sum(obs_station_tc_complex_inf))/float(len(obs_station_tc_complex_inf))\n",
    "    mean_obs_station_no_tc_inf=float(sum(obs_station_no_tc_inf))/float(len(obs_station_no_tc_inf))\n",
    "    \n",
    "    mean_obs_list_tc_inf.append(mean_obs_station_tc_inf)\n",
    "    mean_obs_list_tc_complex_inf.append(mean_obs_station_tc_complex_inf)\n",
    "    mean_obs_list_no_tc_inf.append(mean_obs_station_no_tc_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-colorado",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipped=list(zip(dates,stations,lats,lons,obs))\n",
    "zipped_stations=list(zip(stations1,lats1,lons1,thresholds))\n",
    "\n",
    "trends_list=[]\n",
    "sigs_list=[]\n",
    "mean_obs_list_t1=[]\n",
    "mean_obs_list_t2=[]\n",
    "mean_obs_list_t3=[]\n",
    "mean_obs_list_t4=[]\n",
    "mean_obs_list_t5=[]\n",
    "mean_obs_list_t6=[]\n",
    "mean_obs_list_t7=[]\n",
    "mean_obs_list_t8=[]\n",
    "mean_obs_list_t9=[]\n",
    "mean_obs_list_t10=[]\n",
    "mean_obs_list_t11=[]\n",
    "\n",
    "mean_obs_list_tc=[]\n",
    "mean_obs_list_ar=[]\n",
    "mean_obs_list_other=[]\n",
    "for i in range(len(stations1)):\n",
    "    print(i)\n",
    "    station=stations1[i].values\n",
    "    select_station_t1=[x for x in zipped if x[1]==station and x[0] in dates_t1]\n",
    "    select_station_t2=[x for x in zipped if x[1]==station and x[0] in dates_t2]\n",
    "    select_station_t3=[x for x in zipped if x[1]==station and x[0] in dates_t3]\n",
    "    select_station_t4=[x for x in zipped if x[1]==station and x[0] in dates_t4]\n",
    "    select_station_t5=[x for x in zipped if x[1]==station and x[0] in dates_t5]\n",
    "    select_station_t6=[x for x in zipped if x[1]==station and x[0] in dates_t6]\n",
    "    select_station_t7=[x for x in zipped if x[1]==station and x[0] in dates_t7]\n",
    "    select_station_t8=[x for x in zipped if x[1]==station and x[0] in dates_t8]\n",
    "    select_station_t9=[x for x in zipped if x[1]==station and x[0] in dates_t9]\n",
    "    select_station_t10=[x for x in zipped if x[1]==station and x[0] in dates_t10]\n",
    "    select_station_t11=[x for x in zipped if x[1]==station and x[0] in dates_t11]\n",
    "    \n",
    "    select_station_tc=[x for x in zipped if x[1]==station and x[0] in dates_tc]\n",
    "    select_station_ar=[x for x in zipped if x[1]==station and x[0] in dates_ar]\n",
    "    select_station_other=[x for x in zipped if x[1]==station and x[0] in dates_other]\n",
    "    \n",
    "    obs_station_t1=[x[4] for x in select_station_t1]\n",
    "    obs_station_t2=[x[4] for x in select_station_t2]\n",
    "    obs_station_t3=[x[4] for x in select_station_t3]\n",
    "    obs_station_t4=[x[4] for x in select_station_t4]\n",
    "    obs_station_t5=[x[4] for x in select_station_t5]\n",
    "    obs_station_t6=[x[4] for x in select_station_t6]\n",
    "    obs_station_t7=[x[4] for x in select_station_t7]\n",
    "    obs_station_t8=[x[4] for x in select_station_t8]\n",
    "    obs_station_t9=[x[4] for x in select_station_t9]\n",
    "    obs_station_t10=[x[4] for x in select_station_t10]\n",
    "    obs_station_t11=[x[4] for x in select_station_t11]\n",
    "    \n",
    "    obs_station_tc=[x[4] for x in select_station_tc]\n",
    "    obs_station_ar=[x[4] for x in select_station_ar]\n",
    "    obs_station_other=[x[4] for x in select_station_other]\n",
    "    \n",
    "    mean_obs_station_t1=float(sum(obs_station_t1))/float(len(obs_station_t1))\n",
    "    mean_obs_station_t2=float(sum(obs_station_t2))/float(len(obs_station_t2))\n",
    "    if len(obs_station_t3)>0:\n",
    "        mean_obs_station_t3=float(sum(obs_station_t3))/float(len(obs_station_t3))\n",
    "    else:\n",
    "        mean_obs_station_t3=0\n",
    "    mean_obs_station_t4=float(sum(obs_station_t4))/float(len(obs_station_t4))\n",
    "    mean_obs_station_t5=float(sum(obs_station_t5))/float(len(obs_station_t5))\n",
    "    mean_obs_station_t6=float(sum(obs_station_t6))/float(len(obs_station_t6))\n",
    "    mean_obs_station_t7=float(sum(obs_station_t7))/float(len(obs_station_t7))\n",
    "    mean_obs_station_t8=float(sum(obs_station_t8))/float(len(obs_station_t8))\n",
    "    if len(obs_station_t9)>0:\n",
    "        mean_obs_station_t9=float(sum(obs_station_t9))/float(len(obs_station_t9))\n",
    "    else:\n",
    "        mean_obs_station_t9=0\n",
    "    #mean_obs_station_t10=float(sum(obs_station_t10))/float(len(obs_station_t10))\n",
    "    mean_obs_station_t11=float(sum(obs_station_t11))/float(len(obs_station_t11))\n",
    "    \n",
    "    mean_obs_station_tc=float(sum(obs_station_tc))/float(len(obs_station_tc))\n",
    "    mean_obs_station_ar=float(sum(obs_station_ar))/float(len(obs_station_ar))\n",
    "    mean_obs_station_other=float(sum(obs_station_other))/float(len(obs_station_other))\n",
    "    \n",
    "    mean_obs_list_t1.append(mean_obs_station_t1)\n",
    "    mean_obs_list_t2.append(mean_obs_station_t2)\n",
    "    mean_obs_list_t3.append(mean_obs_station_t3)\n",
    "    mean_obs_list_t4.append(mean_obs_station_t4)\n",
    "    mean_obs_list_t5.append(mean_obs_station_t5)\n",
    "    mean_obs_list_t6.append(mean_obs_station_t6)\n",
    "    mean_obs_list_t7.append(mean_obs_station_t7)\n",
    "    mean_obs_list_t8.append(mean_obs_station_t8)\n",
    "    mean_obs_list_t9.append(mean_obs_station_t9)\n",
    "    #mean_obs_list_t10.append(mean_obs_station_t10)\n",
    "    mean_obs_list_t11.append(mean_obs_station_t11)\n",
    "    \n",
    "    mean_obs_list_tc.append(mean_obs_station_tc)\n",
    "    mean_obs_list_ar.append(mean_obs_station_ar)\n",
    "    mean_obs_list_other.append(mean_obs_station_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to draw grid lines on Lambert Conformal projection; \n",
    "#CREDIT ajdawson on GitHub https://gist.github.com/ajdawson/dd536f786741e987ae4e\n",
    "\n",
    "from copy import copy\n",
    "import shapely.geometry as sgeom\n",
    "def find_side(ls, side):\n",
    "    \"\"\"\n",
    "    Given a shapely LineString which is assumed to be rectangular, return the\n",
    "    line corresponding to a given side of the rectangle.\n",
    "    \n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = ls.bounds\n",
    "    points = {'left': [(minx, miny), (minx, maxy)],\n",
    "              'right': [(maxx, miny), (maxx, maxy)],\n",
    "              'bottom': [(minx, miny), (maxx, miny)],\n",
    "              'top': [(minx, maxy), (maxx, maxy)],}\n",
    "    return sgeom.LineString(points[side])\n",
    "\n",
    "\n",
    "def lambert_xticks(ax, ticks):\n",
    "    \"\"\"Draw ticks on the bottom x-axis of a Lambert Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[0]\n",
    "    lc = lambda t, n, b: np.vstack((np.zeros(n) + t, np.linspace(b[2], b[3], n))).T\n",
    "    xticks, xticklabels = _lambert_ticks(ax, ticks, 'bottom', lc, te)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels([ax.xaxis.get_major_formatter()(xtick) for xtick in xticklabels])\n",
    "    \n",
    "\n",
    "def lambert_yticks(ax, ticks):\n",
    "    \"\"\"Draw ricks on the left y-axis of a Lamber Conformal projection.\"\"\"\n",
    "    te = lambda xy: xy[1]\n",
    "    lc = lambda t, n, b: np.vstack((np.linspace(b[0], b[1], n), np.zeros(n) + t)).T\n",
    "    yticks, yticklabels = _lambert_ticks(ax, ticks, 'left', lc, te)\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([ax.yaxis.get_major_formatter()(ytick) for ytick in yticklabels])\n",
    "def _lambert_ticks(ax, ticks, tick_location, line_constructor, tick_extractor):\n",
    "    \"\"\"Get the tick locations and labels for an axis of a Lambert Conformal projection.\"\"\"\n",
    "    outline_patch = sgeom.LineString(ax.outline_patch.get_path().vertices.tolist())\n",
    "    axis = find_side(outline_patch, tick_location)\n",
    "    n_steps = 30\n",
    "    extent = ax.get_extent(ccrs.PlateCarree())\n",
    "    _ticks = []\n",
    "    for t in ticks:\n",
    "        xy = line_constructor(t, n_steps, extent)\n",
    "        proj_xyz = ax.projection.transform_points(ccrs.Geodetic(), xy[:, 0], xy[:, 1])\n",
    "        xyt = proj_xyz[..., :2]\n",
    "        ls = sgeom.LineString(xyt.tolist())\n",
    "        locs = axis.intersection(ls)\n",
    "        if not locs:\n",
    "            tick = [None]\n",
    "        else:\n",
    "            tick = tick_extractor(locs.xy)\n",
    "        _ticks.append(tick[0])\n",
    "    # Remove ticks that aren't visible:    \n",
    "    ticklabels = copy(ticks)\n",
    "    while True:\n",
    "        try:\n",
    "            index = _ticks.index(None)\n",
    "        except ValueError:\n",
    "            break\n",
    "        _ticks.pop(index)\n",
    "        ticklabels.pop(index)\n",
    "    return _ticks, ticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "#zipped_t1=list(zip(dates,ar_yesno4))#ar-related = green\n",
    "#zipped_t2=list(zip(dates,tc_linked_ar_yesno4))\n",
    "#zipped_t3=list(zip(dates,tc_remnant_linked_ar_yesno4))\n",
    "#zipped_t4=list(zip(dates,tc_yesno4))#tc-related = blue\n",
    "#zipped_t5=list(zip(dates,tc_ar_combo_yesno4))\n",
    "#zipped_t6=list(zip(dates,tc_remnant_ar_combo_yesno4))\n",
    "#zipped_t7=list(zip(dates,tc_remnants_yesno4))\n",
    "#zipped_t8=list(zip(dates,ivt_yesno4))#other IVT-related = grey\n",
    "#zipped_t9=list(zip(dates,tc_linked_ivt_yesno4))\n",
    "#zipped_t10=list(zip(dates,tc_remnant_linked_ivt_yesno4))\n",
    "#zipped_t11=list(zip(dates,other_yesno4))#unspecified = brown\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-84,-66,36,48],crs=ccrs.PlateCarree())\n",
    "\n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-90,-85,-80,-75,-70,-65,-60,-50]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=26)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "\n",
    "cax=ax.scatter(lons1,lats1,s=240,c=mean_obs_list_tc_complex_inf,transform=ccrs.PlateCarree(),vmin=0,vmax=50,cmap=plt.cm.YlGnBu)\n",
    "cbar=plt.colorbar(cax,pad=0,extend='max',fraction=0.046)\n",
    "cbar.ax.tick_params(labelsize=26)\n",
    "cbar.set_label('Mean precipitation (mm/day)',fontsize=24,rotation=90,labelpad=25)\n",
    "ax.set_title('Complex TC influences',fontsize=36)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "ax.text(0.01, 0.99,'n='+str(len(dates_tc_complex_inf)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'neusa_wtype_precip_95composites_90.png')#1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author: Michael Schramm on GitHub\n",
    "#This function is derived from code originally posted by Sat Kumar Tomer\n",
    "#(satkumartomer@gmail.com)\n",
    "#See also: http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm\n",
    "\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as st\n",
    "def mk_test(x, alpha=0.05):\n",
    "    n = len(x)\n",
    "\n",
    "    # calculate S\n",
    "    s = 0\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1, n):\n",
    "            s += np.sign(x[j] - x[k])\n",
    "\n",
    "    # calculate the unique data\n",
    "    unique_x, tp = np.unique(x, return_counts=True)\n",
    "    g = len(unique_x)\n",
    "\n",
    "    # calculate the var(s)\n",
    "    if n == g:  # there is no tie\n",
    "        var_s = (n*(n-1)*(2*n+5))/18\n",
    "    else:  # there are some ties in data\n",
    "        var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18\n",
    "\n",
    "    if s > 0:\n",
    "        z = (s - 1)/np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1)/np.sqrt(var_s)\n",
    "    else: # s == 0:\n",
    "        z = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(z)))  # two tail test\n",
    "    h = abs(z) > norm.ppf(1-alpha/2)\n",
    "\n",
    "    if (z < 0) and h:\n",
    "        trend = 'decreasing'\n",
    "    elif (z > 0) and h:\n",
    "        trend = 'increasing'\n",
    "    else:\n",
    "        trend = 'no trend'\n",
    "\n",
    "    return trend, h, p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a4a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipped_stations=list(zip(stations1,lats1,lons1,thresholds))\n",
    "\n",
    "trends_list_tc_inf=[]\n",
    "trends_list_no_tc_inf=[]\n",
    "\n",
    "sigs_list_tc_inf=[]\n",
    "sigs_list_no_tc_inf=[]\n",
    "\n",
    "sigs_list_tc_infa=[]\n",
    "sigs_list_no_tc_infa=[]\n",
    "\n",
    "size_list_tc_inf=[]\n",
    "size_list_no_tc_inf=[]\n",
    "\n",
    "for i in range(len(stations1)):\n",
    "    print(i)\n",
    "    station=stations1[i].values\n",
    "    \n",
    "    annual_sum_list_tc_inf=[]\n",
    "    annual_sum_list_no_tc_inf=[]\n",
    "    for j in range(len(yrs_neusa)):\n",
    "        year=yrs_neusa[0]+j\n",
    "        print(year)\n",
    "\n",
    "        select_station_tc_inf=[x for x in zipped if x[1]==station and x[0] in dates_tc_inf and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_no_tc_inf=[x for x in zipped if x[1]==station and x[0] in dates_no_tc_inf and pd.to_datetime(x[0]).year==year]\n",
    "        \n",
    "        \n",
    "   \n",
    "            \n",
    "        if len(select_station_tc_inf)>0:\n",
    "            select_obs=[x[4] for x in select_station_tc_inf]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_tc_inf.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_tc_inf.append(0)\n",
    "            \n",
    "        if len(select_station_no_tc_inf)>0:\n",
    "            select_obs=[x[4] for x in select_station_no_tc_inf]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_no_tc_inf.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_no_tc_inf.append(0)\n",
    "    \n",
    "    annual_sum_mean_tc_inf=float(sum(annual_sum_list_tc_inf))/float(len(annual_sum_list_tc_inf))\n",
    "    annual_sum_mean_no_tc_inf=float(sum(annual_sum_list_no_tc_inf))/float(len(annual_sum_list_no_tc_inf))\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_tc_inf if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_tc_inf.append(1)\n",
    "    else:\n",
    "        size_list_tc_inf.append(0)\n",
    "    trend=mk_test(annual_sum_list_tc_inf,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_tc_inf,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_tc_inf)[0]\n",
    "    slope_percent=slope/annual_sum_mean_tc_inf*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_tc_inf.append(slope_percent)\n",
    "    sigs_list_tc_inf.append(sig)\n",
    "    sigs_list_tc_infa.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_no_tc_inf if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_no_tc_inf.append(1)\n",
    "    else:\n",
    "        size_list_no_tc_inf.append(0)\n",
    "    trend=mk_test(annual_sum_list_no_tc_inf,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_no_tc_inf,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_no_tc_inf)[0]\n",
    "    slope_percent=slope/annual_sum_mean_no_tc_inf*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_no_tc_inf.append(slope_percent)\n",
    "    sigs_list_no_tc_inf.append(sig)\n",
    "    sigs_list_no_tc_infa.append(siga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-license",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zipped_stations=list(zip(stations1,lats1,lons1,thresholds))\n",
    "trends_list_t1=[]\n",
    "trends_list_t2=[]\n",
    "trends_list_t3=[]\n",
    "trends_list_t4=[]\n",
    "trends_list_t5=[]\n",
    "trends_list_t6=[]\n",
    "trends_list_t7=[]\n",
    "trends_list_t8=[]\n",
    "trends_list_t9=[]\n",
    "trends_list_t10=[]\n",
    "trends_list_t11=[]\n",
    "\n",
    "trends_list_tc=[]\n",
    "trends_list_ar=[]\n",
    "trends_list_other=[]\n",
    "\n",
    "sigs_list_t1=[]\n",
    "sigs_list_t2=[]\n",
    "sigs_list_t3=[]\n",
    "sigs_list_t4=[]\n",
    "sigs_list_t5=[]\n",
    "sigs_list_t6=[]\n",
    "sigs_list_t7=[]\n",
    "sigs_list_t8=[]\n",
    "sigs_list_t9=[]\n",
    "sigs_list_t10=[]\n",
    "sigs_list_t11=[]\n",
    "\n",
    "sigs_list_tc=[]\n",
    "sigs_list_ar=[]\n",
    "sigs_list_other=[]\n",
    "\n",
    "sigs_list_t1a=[]\n",
    "sigs_list_t2a=[]\n",
    "sigs_list_t3a=[]\n",
    "sigs_list_t4a=[]\n",
    "sigs_list_t5a=[]\n",
    "sigs_list_t6a=[]\n",
    "sigs_list_t7a=[]\n",
    "sigs_list_t8a=[]\n",
    "sigs_list_t9a=[]\n",
    "sigs_list_t10a=[]\n",
    "sigs_list_t11a=[]\n",
    "\n",
    "sigs_list_tca=[]\n",
    "sigs_list_ara=[]\n",
    "sigs_list_othera=[]\n",
    "\n",
    "size_list_t1=[]\n",
    "size_list_t2=[]\n",
    "size_list_t3=[]\n",
    "size_list_t4=[]\n",
    "size_list_t5=[]\n",
    "size_list_t6=[]\n",
    "size_list_t7=[]\n",
    "size_list_t8=[]\n",
    "size_list_t9=[]\n",
    "size_list_t10=[]\n",
    "size_list_t11=[]\n",
    "size_list_tc=[]\n",
    "size_list_ar=[]\n",
    "size_list_other=[]\n",
    "print(dates_t1)\n",
    "print(dates_t4)\n",
    "print(len(dates_t1))\n",
    "print(len(dates_t4))\n",
    "for i in range(len(stations1)):\n",
    "    print(i)\n",
    "    station=stations1[i].values\n",
    "    annual_sum_list_t1=[]\n",
    "    annual_sum_list_t2=[]\n",
    "    annual_sum_list_t3=[]\n",
    "    annual_sum_list_t4=[]\n",
    "    annual_sum_list_t5=[]\n",
    "    annual_sum_list_t6=[]\n",
    "    annual_sum_list_t7=[]\n",
    "    annual_sum_list_t8=[]\n",
    "    annual_sum_list_t9=[]\n",
    "    annual_sum_list_t10=[]\n",
    "    annual_sum_list_t11=[]\n",
    "    \n",
    "    annual_sum_list_tc=[]\n",
    "    annual_sum_list_ar=[]\n",
    "    annual_sum_list_other=[]\n",
    "    for j in range(len(yrs_neusa)):\n",
    "        year=yrs_neusa[0]+j\n",
    "        print(year)\n",
    "        select_station_t1=[x for x in zipped if x[1]==station and x[0] in dates_t1 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t2=[x for x in zipped if x[1]==station and x[0] in dates_t2 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t3=[x for x in zipped if x[1]==station and x[0] in dates_t3 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t4=[x for x in zipped if x[1]==station and x[0] in dates_t4 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t5=[x for x in zipped if x[1]==station and x[0] in dates_t5 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t6=[x for x in zipped if x[1]==station and x[0] in dates_t6 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t7=[x for x in zipped if x[1]==station and x[0] in dates_t7 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t8=[x for x in zipped if x[1]==station and x[0] in dates_t8 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t9=[x for x in zipped if x[1]==station and x[0] in dates_t9 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t10=[x for x in zipped if x[1]==station and x[0] in dates_t10 and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_t11=[x for x in zipped if x[1]==station and x[0] in dates_t11 and pd.to_datetime(x[0]).year==year]\n",
    "\n",
    "\n",
    "        select_station_tc=[x for x in zipped if x[1]==station and x[0] in dates_tc and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_ar=[x for x in zipped if x[1]==station and x[0] in dates_ar and pd.to_datetime(x[0]).year==year]\n",
    "        select_station_other=[x for x in zipped if x[1]==station and x[0] in dates_other and pd.to_datetime(x[0]).year==year]\n",
    "        \n",
    "        if len(select_station_t1)>0:\n",
    "            select_obs=[x[4] for x in select_station_t1]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t1.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t1.append(0)\n",
    "            \n",
    "        if len(select_station_t2)>0:\n",
    "            select_obs=[x[4] for x in select_station_t2]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t2.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t2.append(0)\n",
    "            \n",
    "        if len(select_station_t3)>0:\n",
    "            select_obs=[x[4] for x in select_station_t3]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t3.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t3.append(0)\n",
    "            \n",
    "        if len(select_station_t4)>0:\n",
    "            select_obs=[x[4] for x in select_station_t4]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t4.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t4.append(0)\n",
    "            \n",
    "        if len(select_station_t5)>0:\n",
    "            select_obs=[x[4] for x in select_station_t5]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t5.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t5.append(0)\n",
    "            \n",
    "        if len(select_station_t6)>0:\n",
    "            select_obs=[x[4] for x in select_station_t6]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t6.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t6.append(0)\n",
    "            \n",
    "        if len(select_station_t7)>0:\n",
    "            select_obs=[x[4] for x in select_station_t7]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t7.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t7.append(0)\n",
    "            \n",
    "        if len(select_station_t8)>0:\n",
    "            select_obs=[x[4] for x in select_station_t8]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t8.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t8.append(0)\n",
    "            \n",
    "        if len(select_station_t9)>0:\n",
    "            select_obs=[x[4] for x in select_station_t9]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t9.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t9.append(0)\n",
    "            \n",
    "        if len(select_station_t10)>0:\n",
    "            select_obs=[x[4] for x in select_station_t10]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t10.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t10.append(0)\n",
    "            \n",
    "        if len(select_station_t11)>0:\n",
    "            select_obs=[x[4] for x in select_station_t11]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_t11.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_t11.append(0)\n",
    "            \n",
    "        if len(select_station_tc)>0:\n",
    "            select_obs=[x[4] for x in select_station_tc]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_tc.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_tc.append(0)\n",
    "            \n",
    "        if len(select_station_ar)>0:\n",
    "            select_obs=[x[4] for x in select_station_ar]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_ar.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_ar.append(0)\n",
    "            \n",
    "        if len(select_station_other)>0:\n",
    "            select_obs=[x[4] for x in select_station_other]\n",
    "            annual_sum=sum(select_obs)\n",
    "            annual_sum=annual_sum*30./91.#monthly\n",
    "            annual_sum_list_other.append(annual_sum)\n",
    "        else:\n",
    "            annual_sum_list_other.append(0)\n",
    "\n",
    "    annual_sum_mean_t1=float(sum(annual_sum_list_t1))/float(len(annual_sum_list_t1))\n",
    "    annual_sum_mean_t2=float(sum(annual_sum_list_t2))/float(len(annual_sum_list_t2))\n",
    "    annual_sum_mean_t3=float(sum(annual_sum_list_t3))/float(len(annual_sum_list_t3))\n",
    "    annual_sum_mean_t4=float(sum(annual_sum_list_t4))/float(len(annual_sum_list_t4))\n",
    "    annual_sum_mean_t5=float(sum(annual_sum_list_t5))/float(len(annual_sum_list_t5))\n",
    "    annual_sum_mean_t6=float(sum(annual_sum_list_t6))/float(len(annual_sum_list_t6))\n",
    "    annual_sum_mean_t7=float(sum(annual_sum_list_t7))/float(len(annual_sum_list_t7))\n",
    "    annual_sum_mean_t8=float(sum(annual_sum_list_t8))/float(len(annual_sum_list_t8))\n",
    "    annual_sum_mean_t9=float(sum(annual_sum_list_t9))/float(len(annual_sum_list_t9))\n",
    "    annual_sum_mean_t10=float(sum(annual_sum_list_t10))/float(len(annual_sum_list_t10))\n",
    "    annual_sum_mean_t11=float(sum(annual_sum_list_t11))/float(len(annual_sum_list_t11))\n",
    "    \n",
    "    annual_sum_mean_tc=float(sum(annual_sum_list_tc))/float(len(annual_sum_list_tc))\n",
    "    annual_sum_mean_ar=float(sum(annual_sum_list_ar))/float(len(annual_sum_list_ar))\n",
    "    annual_sum_mean_other=float(sum(annual_sum_list_other))/float(len(annual_sum_list_other))\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t1 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t1.append(1)\n",
    "    else:\n",
    "        size_list_t1.append(0)\n",
    "    trend=mk_test(annual_sum_list_t1,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t1,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t1)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t1*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0  \n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t1.append(slope_percent)\n",
    "    sigs_list_t1.append(sig)\n",
    "    sigs_list_t1a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t2 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t2.append(1)\n",
    "    else:\n",
    "        size_list_t2.append(0)\n",
    "    trend=mk_test(annual_sum_list_t2,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t2,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t2)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t2*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t2.append(slope_percent)\n",
    "    sigs_list_t2.append(sig)\n",
    "    sigs_list_t2a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t3 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t3.append(1)\n",
    "    else:\n",
    "        size_list_t3.append(0)\n",
    "    trend=mk_test(annual_sum_list_t3,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t3,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t3)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t3*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t3.append(slope_percent)\n",
    "    sigs_list_t3.append(sig)\n",
    "    sigs_list_t3a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t4 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t4.append(1)\n",
    "    else:\n",
    "        size_list_t4.append(0)\n",
    "    trend=mk_test(annual_sum_list_t4,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t4,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t4)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t4*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t4.append(slope_percent)\n",
    "    sigs_list_t4.append(sig)\n",
    "    sigs_list_t4a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t5 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t5.append(1)\n",
    "    else:\n",
    "        size_list_t5.append(0)\n",
    "    trend=mk_test(annual_sum_list_t5,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t5,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t5)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t5*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t5.append(slope_percent)\n",
    "    sigs_list_t5.append(sig)\n",
    "    sigs_list_t5a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t6 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t6.append(1)\n",
    "    else:\n",
    "        size_list_t6.append(0)\n",
    "    trend=mk_test(annual_sum_list_t6,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t6,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t6)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t6*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t6.append(slope_percent)\n",
    "    sigs_list_t6.append(sig)\n",
    "    sigs_list_t6a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t7 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t7.append(1)\n",
    "    else:\n",
    "        size_list_t7.append(0)\n",
    "    trend=mk_test(annual_sum_list_t7,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t7,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t7)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t7*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t7.append(slope_percent)\n",
    "    sigs_list_t7.append(sig)\n",
    "    sigs_list_t7a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t8 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t8.append(1)\n",
    "    else:\n",
    "        size_list_t8.append(0)\n",
    "    trend=mk_test(annual_sum_list_t8,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t8,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t8)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t8*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t8.append(slope_percent)\n",
    "    sigs_list_t8.append(sig)\n",
    "    sigs_list_t8a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t9 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t9.append(1)\n",
    "    else:\n",
    "        size_list_t9.append(0)\n",
    "    trend=mk_test(annual_sum_list_t9,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t9,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t9)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t9*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t9.append(slope_percent)\n",
    "    sigs_list_t9.append(sig)\n",
    "    sigs_list_t9a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t10 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t10.append(1)\n",
    "    else:\n",
    "        size_list_t10.append(0)\n",
    "    trend=mk_test(annual_sum_list_t10,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t10,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t10)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t10*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t10.append(slope_percent)\n",
    "    sigs_list_t10.append(sig)\n",
    "    sigs_list_t10a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_t11 if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_t11.append(1)\n",
    "    else:\n",
    "        size_list_t11.append(0)\n",
    "    trend=mk_test(annual_sum_list_t11,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_t11,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_t11)[0]\n",
    "    slope_percent=slope/annual_sum_mean_t11*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_t11.append(slope_percent)\n",
    "    sigs_list_t11.append(sig)\n",
    "    sigs_list_t11a.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_tc if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_tc.append(1)\n",
    "    else:\n",
    "        size_list_tc.append(0)\n",
    "    trend=mk_test(annual_sum_list_tc,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_tc,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_tc)[0]\n",
    "    slope_percent=slope/annual_sum_mean_tc*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_tc.append(slope_percent)\n",
    "    sigs_list_tc.append(sig)\n",
    "    sigs_list_tca.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_ar if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_ar.append(1)\n",
    "    else:\n",
    "        size_list_ar.append(0)\n",
    "    trend=mk_test(annual_sum_list_ar,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_ar,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_ar)[0]\n",
    "    slope_percent=slope/annual_sum_mean_ar*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_ar.append(slope_percent)\n",
    "    sigs_list_ar.append(sig)\n",
    "    sigs_list_ara.append(siga)\n",
    "    \n",
    "    nonzero=len([x for x in annual_sum_list_other if x>0])\n",
    "    if nonzero>=5:\n",
    "        size_list_other.append(1)\n",
    "    else:\n",
    "        size_list_other.append(0)\n",
    "    trend=mk_test(annual_sum_list_other,alpha=0.05)[0]\n",
    "    trenda=mk_test(annual_sum_list_other,alpha=0.1)[0]\n",
    "    slope=st.linregress(yrs_neusa,annual_sum_list_other)[0]\n",
    "    slope_percent=slope/annual_sum_mean_other*100.\n",
    "    if trend=='increasing':\n",
    "        sig=1\n",
    "    elif trend=='decreasing':\n",
    "        sig=-1\n",
    "    else:\n",
    "        sig=0\n",
    "    if trenda=='increasing':\n",
    "        siga=1\n",
    "    elif trenda=='decreasing':\n",
    "        siga=-1\n",
    "    else:\n",
    "        siga=0\n",
    "    trends_list_other.append(slope_percent)\n",
    "    sigs_list_other.append(sig)\n",
    "    sigs_list_othera.append(siga)\n",
    "print(trends_list_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "clon=-70\n",
    "clat=35\n",
    "proj_map = ccrs.LambertConformal(central_longitude=clon, central_latitude=clat)\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax=plt.subplot(1,1,1,projection=proj_map)\n",
    "\n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.STATES.with_scale('10m'),alpha=0.3)\n",
    "ax.add_feature(cfeature.LAKES.with_scale('50m'))\n",
    "countries = cfeature.NaturalEarthFeature(category='cultural',name='admin_0_boundary_lines_land',scale='50m',facecolor='none')\n",
    "ax.add_feature(countries)\n",
    "ax.set_extent([-84,-66,36,48],crs=ccrs.PlateCarree())\n",
    "\n",
    "sigs_list=sigs_list_tc_inf.copy()#no_tc_inf\n",
    "sigs_lista=sigs_list_tc_infa.copy()\n",
    "trends_list=trends_list_tc_inf.copy()\n",
    "size_list=size_list_tc_inf.copy()\n",
    "dates_list=dates_tc_inf.copy()\n",
    "\n",
    "for i in range(len(sigs_list)):\n",
    "    if size_list[i]==0:\n",
    "        trends_list[i]=np.nan\n",
    "        \n",
    "for i in range(len(sigs_lista)):\n",
    "    sig=sigs_lista[i]\n",
    "    if sig in [-1,1] and size_list[i]==1:#convert to mm\n",
    "        ax.plot(lons1[i],lats1[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='grey',markeredgewidth=2,markersize=28)\n",
    "    \n",
    "for i in range(len(sigs_list)):\n",
    "    sig=sigs_list[i]\n",
    "    if sig in [-1,1] and size_list[i]==1:#convert to mm\n",
    "        ax.plot(lons1[i],lats1[i],transform=ccrs.PlateCarree(),marker='o',markerfacecolor='None',markeredgecolor='k',markeredgewidth=2,markersize=28)\n",
    "    \n",
    "# *must* call draw in order to get the axis boundary used to add ticks:\n",
    "fig.canvas.draw()\n",
    "\n",
    "#zipped_t1=list(zip(dates,ar_yesno4))#ar-related = green\n",
    "#zipped_t2=list(zip(dates,tc_linked_ar_yesno4))\n",
    "#zipped_t3=list(zip(dates,tc_remnant_linked_ar_yesno4))\n",
    "#zipped_t4=list(zip(dates,tc_yesno4))#tc-related = blue\n",
    "#zipped_t5=list(zip(dates,tc_ar_combo_yesno4))\n",
    "#zipped_t6=list(zip(dates,tc_remnant_ar_combo_yesno4))\n",
    "#zipped_t7=list(zip(dates,tc_remnants_yesno4))\n",
    "#zipped_t8=list(zip(dates,ivt_yesno4))#other IVT-related = grey\n",
    "#zipped_t9=list(zip(dates,tc_linked_ivt_yesno4))\n",
    "#zipped_t10=list(zip(dates,tc_remnant_linked_ivt_yesno4))\n",
    "#zipped_t11=list(zip(dates,other_yesno4))#unspecified = brown\n",
    "\n",
    "# Define gridline locations and draw the lines using cartopy's built-in gridliner:\n",
    "xticks = [-90,-85,-80,-75,-70,-65,-60,-50]\n",
    "yticks = [5,10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "ax.gridlines(xlocs=xticks, ylocs=yticks,alpha=0.5)\n",
    "ax.tick_params(labelsize=26)\n",
    "# Label the end-points of the gridlines using the custom tick makers:\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER) \n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "lambert_xticks(ax, xticks)\n",
    "lambert_yticks(ax, yticks)\n",
    "cax=ax.scatter(lons1,lats1,s=240,c=trends_list,transform=ccrs.PlateCarree(),vmin=-4.5,vmax=4.5,cmap=plt.cm.seismic_r,zorder=10)\n",
    "for i in range(len(trends_list)):\n",
    "    lon=lons1[i]\n",
    "    lat=lats1[i]\n",
    "    size=size_list[i]\n",
    "    if size==0:\n",
    "        if trends_list[i]>0:\n",
    "            print('POS')\n",
    "            ax.plot(lon,lat,marker='+',markersize=8,color='k')\n",
    "        if trends_list[i]<0:\n",
    "            print('NEG')\n",
    "            ax.plot(lon,lat,marker='_',markersize=8,color='k')\n",
    "cbar=plt.colorbar(cax,pad=0,extend='both',fraction=0.046)\n",
    "cbar.ax.tick_params(labelsize=26)\n",
    "cbar.set_label('Cumulative precipitation trend (%/year)',fontsize=24,rotation=90,labelpad=15)\n",
    "ax.set_title('Any TC influences',fontsize=36,pad=10)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=1.0)\n",
    "ax.text(0.01, 0.99,'n='+str(len(dates_list)), transform=ax.transAxes, fontsize=28,verticalalignment='top', bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'neusa_wtype_precip_trend_95composites_101.png')#1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-backing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
