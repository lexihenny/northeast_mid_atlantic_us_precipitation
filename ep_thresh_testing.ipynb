{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os,errno\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author: Michael Schramm on GitHub\n",
    "#This function is derived from code originally posted by Sat Kumar Tomer\n",
    "#(satkumartomer@gmail.com)\n",
    "#See also: http://vsp.pnnl.gov/help/Vsample/Design_Trend_Mann_Kendall.htm\n",
    "\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as st\n",
    "def mk_test(x, alpha=0.05):\n",
    "    n = len(x)\n",
    "\n",
    "    # calculate S\n",
    "    s = 0\n",
    "    for k in range(n-1):\n",
    "        for j in range(k+1, n):\n",
    "            s += np.sign(x[j] - x[k])\n",
    "\n",
    "    # calculate the unique data\n",
    "    unique_x, tp = np.unique(x, return_counts=True)\n",
    "    g = len(unique_x)\n",
    "\n",
    "    # calculate the var(s)\n",
    "    if n == g:  # there is no tie\n",
    "        var_s = (n*(n-1)*(2*n+5))/18\n",
    "    else:  # there are some ties in data\n",
    "        var_s = (n*(n-1)*(2*n+5) - np.sum(tp*(tp-1)*(2*tp+5)))/18\n",
    "\n",
    "    if s > 0:\n",
    "        z = (s - 1)/np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1)/np.sqrt(var_s)\n",
    "    else: # s == 0:\n",
    "        z = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2*(1-norm.cdf(abs(z)))  # two tail test\n",
    "    h = abs(z) > norm.ppf(1-alpha/2)\n",
    "\n",
    "    if (z < 0) and h:\n",
    "        trend = 'decreasing'\n",
    "    elif (z > 0) and h:\n",
    "        trend = 'increasing'\n",
    "    else:\n",
    "        trend = 'no trend'\n",
    "\n",
    "    return trend, h, p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(dir+'extreme_days_ghcnd_winter_95_80.nc')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#names=[dir+'extreme_days_ghcnd_90station_70area.nc',dir+'extreme_days_ghcnd_90station_80area.nc',\n",
    "#       dir+'extreme_days_ghcnd_90station_90area.nc',dir+'extreme_days_ghcnd_95station_70area.nc',\n",
    "#      dir+'extreme_days_ghcnd_95station_80area.nc',dir+'extreme_days_ghcnd_95station_90area.nc',\n",
    "#      dir+'extreme_days_ghcnd_99station_70area.nc',dir+'extreme_days_ghcnd_99station_80area.nc',\n",
    "#      dir+'extreme_days_ghcnd_99station_90area.nc']\n",
    "\n",
    "names_winter=[dir+'extreme_days_ghcnd_95_80_winter.nc',dir+'extreme_days_ghcnd_95_90_winter.nc',\n",
    "      dir+'extreme_days_ghcnd_95_95_winter.nc',dir+'extreme_days_ghcnd_99_80_winter.nc',\n",
    "      dir+'extreme_days_ghcnd_99_90_winter.nc',dir+'extreme_days_ghcnd_99_95_winter.nc']\n",
    "\n",
    "names_spring=[dir+'extreme_days_ghcnd_95_80_spring.nc',dir+'extreme_days_ghcnd_95_90_spring.nc',\n",
    "      dir+'extreme_days_ghcnd_95_95_spring.nc',dir+'extreme_days_ghcnd_99_80_spring.nc',\n",
    "      dir+'extreme_days_ghcnd_99_90_spring.nc',dir+'extreme_days_ghcnd_99_95_spring.nc']\n",
    "\n",
    "names_summer=[dir+'extreme_days_ghcnd_95_80_summer.nc',dir+'extreme_days_ghcnd_95_90_summer.nc',\n",
    "      dir+'extreme_days_ghcnd_95_95_summer.nc',dir+'extreme_days_ghcnd_99_80_summer.nc',\n",
    "      dir+'extreme_days_ghcnd_99_90_summer.nc',dir+'extreme_days_ghcnd_99_95_summer.nc']\n",
    "\n",
    "names_fall=[dir+'extreme_days_ghcnd_95_80_fall.nc',dir+'extreme_days_ghcnd_95_90_fall.nc',\n",
    "      dir+'extreme_days_ghcnd_95_95_fall.nc',dir+'extreme_days_ghcnd_99_80_fall.nc',\n",
    "      dir+'extreme_days_ghcnd_99_90_fall.nc',dir+'extreme_days_ghcnd_99_95_fall.nc']\n",
    "\n",
    "names_annual=[dir+'extreme_days_ghcnd_95_80_annual.nc',dir+'extreme_days_ghcnd_95_90_annual.nc',\n",
    "      dir+'extreme_days_ghcnd_95_95_annual.nc',dir+'extreme_days_ghcnd_99_80_annual.nc',\n",
    "      dir+'extreme_days_ghcnd_99_90_annual.nc',dir+'extreme_days_ghcnd_99_95_annual.nc']\n",
    "\n",
    "\n",
    "seasons_list=['Winter','Spring','Summer','Fall','annual']\n",
    "\n",
    "dp=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "stations=dp.stations.values.tolist()\n",
    "print(len(stations))\n",
    "\n",
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "\n",
    "for l1 in range(len(seasons_list)):\n",
    "    season=seasons_list[l1]\n",
    "    days_list=[]\n",
    "    percent_trend_list=[]\n",
    "    mk_list=[]\n",
    "    p_value_list=[]\n",
    "    if season=='Winter':\n",
    "        filenames=names_winter\n",
    "        winter_length_list=[]\n",
    "        for j in range(len(yrs_neusa)):\n",
    "            if yrs_neusa[j]%4==0:\n",
    "                winter_length_list.append(91.)\n",
    "            else:\n",
    "                winter_length_list.append(90.)\n",
    "    if season=='Spring':\n",
    "        filenames=names_spring\n",
    "        season_length=92.\n",
    "    if season=='Summer':\n",
    "        filenames=names_summer\n",
    "        season_length=92.\n",
    "    if season=='Fall':\n",
    "        filenames=names_fall\n",
    "        season_length=91.\n",
    "    if season=='annual':\n",
    "        filenames=names_annual\n",
    "        season_length=91.\n",
    "    \n",
    "    \n",
    "    for l2 in range(len(filenames)):\n",
    "        name=filenames[l2]\n",
    "    \n",
    "        ds=xr.open_dataset(name)\n",
    "        dates=ds['dates'].values\n",
    "        lats=ds['lats']\n",
    "        lons=ds['lons']\n",
    "        obs=ds['obs'].values.tolist()\n",
    "        zipped=list(zip(dates,obs))\n",
    "        dates_pd=pd.DatetimeIndex(dates)\n",
    "        dates_unique=dates_pd.unique()\n",
    "        print(len(dates_unique))\n",
    "        years=dates_unique.year.values.tolist()\n",
    "\n",
    "        mean_obs_list=[]\n",
    "        for i in range(len(dates_unique)):\n",
    "            #print(i)\n",
    "            select_date=[x for x in zipped if x[0]==dates_unique[i]]        \n",
    "            obs_date=[x[-1] for x in select_date]\n",
    "            obs_defined=[x for x in obs_date if 0<=x<=2000]\n",
    "            #if len(obs_defined)<len(stations):\n",
    "            #    print('MISSING VALUES')\n",
    "            #    print(str(len(obs_defined))+'/'+str(len(stations)))\n",
    "            mean_obs=float(sum(obs_defined))/float(len(obs_defined))\n",
    "            mean_obs_list.append(mean_obs)\n",
    "\n",
    "        zipped_years=list(zip(years,mean_obs_list))\n",
    "        values_list=[]\n",
    "        for i in range(len(yrs_neusa)):\n",
    "            #print(i)\n",
    "            select_year=[x for x in zipped_years if x[0]==yrs_neusa[i]]\n",
    "            obs_year=[x[1] for x in select_year]\n",
    "            if len(obs_year)>1:\n",
    "                if season=='Winter':\n",
    "                    total_year=sum(obs_year)*30./winter_length_list[i]\n",
    "                else:\n",
    "                    total_year=sum(obs_year)*30./season_length\n",
    "            if len(obs_year)==1:\n",
    "                if season=='Winter':\n",
    "                    total_year=obs_year[0]*30./winter_length_list[i]\n",
    "                else:\n",
    "                    total_year=obs_year[0]*30./season_length\n",
    "            if len(obs_year)==0:\n",
    "                total_year=0\n",
    "            values_list.append(total_year)\n",
    "\n",
    "        r1=st.linregress(np.arange(len(yrs_neusa)),values_list)\n",
    "        mean_value=float(sum(values_list))/float(len(values_list))\n",
    "        slope_percent_1b=round(r1[0]/mean_value*100.,2)\n",
    "        print(slope_percent_1b)\n",
    "        mk_result=mk_test(values_list,alpha=0.05)\n",
    "        mk_result1=mk_test(values_list,alpha=0.10)\n",
    "\n",
    "        days_list.append(len(dates_unique))\n",
    "        percent_trend_list.append(slope_percent_1b)\n",
    "        p_value_list.append(round(r1[3],2))\n",
    "        if mk_result[0] in ['increasing','decreasing']:\n",
    "            mk_list.append('p<0.05')\n",
    "        elif mk_result1[0] in ['increasing','decreasing']:\n",
    "            mk_list.append('p<0.10')\n",
    "        else:\n",
    "            mk_list.append('None')\n",
    "\n",
    "        if 1==0:\n",
    "            fig=plt.figure(figsize=(8,8))\n",
    "            ax=plt.subplot(1,1,1)\n",
    "            ax.plot(yrs_neusa,values_list,color='r',linewidth=1.0,linestyle='solid',label='Fall EP day sum')\n",
    "            ax.plot(yrs_neusa,[r1[0]*x+r1[1] for x in np.arange(len(yrs_neusa))],color='k',linestyle='--',linewidth=1.5,label='y='+str(round(r1[0],2))+'x+'+str(round(r1[1],2))+', p='+str(round(r1[3],2)))\n",
    "            ax.tick_params(labelsize=14)\n",
    "            ax.set_xlabel('Year',fontsize=14)\n",
    "            ax.set_ylabel('Monthly spatially-averaged precipitation (mm)',fontsize=14)\n",
    "            ax.set_title('NEUSA Extreme Precipitation Day Totals',fontsize=18)\n",
    "            plt.legend(loc='upper left',fontsize=12)\n",
    "            plt.show()\n",
    "\n",
    "    #plt.close()\n",
    "    station_thresh_list=['95','95','95','99','99','99']\n",
    "    area_thresh_list=['80','90','95','80','90','95']\n",
    "\n",
    "    cell_text=[]\n",
    "    for i in range(6):\n",
    "        row=[station_thresh_list[i],area_thresh_list[i],days_list[i],percent_trend_list[i],p_value_list[i],mk_list[i]]\n",
    "        cell_text.append(row)\n",
    "    print(cell_text)\n",
    "    columns=['Station extreme threshold','Total extreme threshold','Number of days','Percent trend','p-value','M-K significance']\n",
    "\n",
    "    from matplotlib.font_manager import FontProperties\n",
    "    fig, ax = plt.subplots() \n",
    "    ax.set_axis_off() \n",
    "    table=ax.table(cellText=cell_text,rowLabels=['']*6,colLabels=columns,cellLoc ='center',loc ='upper left')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(14)\n",
    "    table.scale(3.2, 1.5)\n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        if (row == 0) or (col == -1):\n",
    "            #cell.set_text_props(fontproperties=FontProperties(size=17))\n",
    "            cell.get_text().set_fontsize(20)\n",
    "            cell.set_text_props(fontproperties=FontProperties(weight='bold'))\n",
    "        else:\n",
    "            cell.get_text().set_fontsize(14)\n",
    "    table.auto_set_column_width(col=list(range(5)))\n",
    "    if season=='annual':\n",
    "        ax.text(1.0,1.02,'Fall (annual threshold)',fontsize=20)\n",
    "    else:\n",
    "        ax.text(1.1,1.02,season,fontsize=20)\n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "    #fig.savefig(dir+'climo_neusa_sensitivity_tables_'+season+'.png',bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a04dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
