{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import os,errno\n",
    "import sys\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from scipy.ndimage.measurements import label\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import scipy.stats as st\n",
    "import geopy.distance\n",
    "%matplotlib inline\n",
    "\n",
    "dir2='/thorncroftlab_rit/ahenny/rain/'\n",
    "dir1='/thorncroftlab_rit/ahenny/rain/US/ghcnd_all/'\n",
    "dir='/thorncroftlab_rit/ahenny/rain/DISSERTATION_SCRIPTS_RESULTS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-charter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 1==1:#get spatially-averaged rainfall for EP days in NEUSA\n",
    "    dp=xr.open_dataset(dir+'station_numbers_95.nc')\n",
    "    stations=dp.stations.values.tolist()\n",
    "    print(len(stations))\n",
    "\n",
    "    yrs_neusa=np.arange(1979,2020,1)\n",
    "    ds=xr.open_dataset(dir+'extreme_days_ghcnd_99station_80area95.nc')\n",
    "    dates=ds['dates'].values\n",
    "    lats=ds['lats']\n",
    "    lons=ds['lons']\n",
    "    obs=ds['obs'].values.tolist()\n",
    "    zipped=list(zip(dates,obs))\n",
    "    dates_pd=pd.DatetimeIndex(dates)\n",
    "    dates_unique=dates_pd.unique()\n",
    "    years=dates_unique.year.values.tolist()\n",
    "    \n",
    "    mean_obs_list=[]\n",
    "    for i in range(len(dates_unique)):\n",
    "        print(i)\n",
    "        select_date=[x for x in zipped if x[0]==dates_unique[i]]        \n",
    "        obs_date=[x[-1] for x in select_date]\n",
    "        obs_defined=[x for x in obs_date if 0<=x<=2000]\n",
    "        #if len(obs_defined)<len(stations):\n",
    "        #    print('MISSING VALUES')\n",
    "        #    print(str(len(obs_defined))+'/'+str(len(stations)))\n",
    "        mean_obs=float(sum(obs_defined))/float(len(obs_defined))\n",
    "        mean_obs_list.append(mean_obs)\n",
    "if 1==0:#Taiwan; ignore\n",
    "    ds=xr.open_dataset(dir+'ls_extreme_rain_taiwan.nc')\n",
    "    p=ds['large_scale_extreme_rain_all']#total rainfall on ER days\n",
    "    threshold=ds['threshold_99']\n",
    "    dates=ds.large_scale_extreme_days\n",
    "    print(dates)\n",
    "    mean_obs_list=p.mean(dim=('lat','lon'),skipna=True).values.tolist()\n",
    "    print(mean_obs_list)\n",
    "    dates_pd=pd.DatetimeIndex(dates.values)\n",
    "    years=[x.year for x in dates_pd]\n",
    "    print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1=xr.open_dataset(dir+'neusa_ep_days_stats_var90_station95.nc')\n",
    "ar_yesno1=ds1['ar_yesno'].values.tolist()\n",
    "ivt_yesno1=ds1['ivt_yesno'].values.tolist()\n",
    "tc_yesno1=ds1['tc_yesno'].values.tolist()\n",
    "other_yesno1=ds1['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno1=ds1['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno1=ds1['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno1=ds1['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno1=ds1['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno1=ds1['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno1=ds1['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno1=ds1['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ds2=xr.open_dataset(dir+'neusa_ep_days_stats_var925_station95.nc')\n",
    "ar_yesno2=ds2['ar_yesno'].values.tolist()\n",
    "ivt_yesno2=ds2['ivt_yesno'].values.tolist()\n",
    "tc_yesno2=ds2['tc_yesno'].values.tolist()\n",
    "other_yesno2=ds2['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno2=ds2['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno2=ds2['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno2=ds2['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno2=ds2['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno2=ds2['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno2=ds2['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno2=ds2['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ds3=xr.open_dataset(dir+'neusa_ep_days_stats_var95_station95.nc')\n",
    "ar_yesno3=ds3['ar_yesno'].values.tolist()\n",
    "ivt_yesno3=ds3['ivt_yesno'].values.tolist()\n",
    "tc_yesno3=ds3['tc_yesno'].values.tolist()\n",
    "other_yesno3=ds3['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno3=ds3['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno3=ds3['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno3=ds3['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno3=ds3['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno3=ds3['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno3=ds3['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno3=ds3['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ds4=xr.open_dataset(dir+'neusa_ep_days_stats_var95const_station95.nc')\n",
    "ar_yesno4=ds4['ar_yesno'].values.tolist()\n",
    "ivt_yesno4=ds4['ivt_yesno'].values.tolist()\n",
    "tc_yesno4=ds4['tc_yesno'].values.tolist()\n",
    "other_yesno4=ds4['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno4=ds4['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno4=ds4['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno4=ds4['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno4=ds4['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno4=ds4['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno4=ds4['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno4=ds4['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ds5=xr.open_dataset(dir+'neusa_ep_days_stats_var975_station95.nc')\n",
    "ar_yesno5=ds5['ar_yesno'].values.tolist()\n",
    "ivt_yesno5=ds5['ivt_yesno'].values.tolist()\n",
    "tc_yesno5=ds5['tc_yesno'].values.tolist()\n",
    "other_yesno5=ds5['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno5=ds5['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno5=ds5['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno5=ds5['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno5=ds5['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno5=ds5['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno5=ds5['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno5=ds5['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ds6=xr.open_dataset(dir+'neusa_ep_days_stats_var99_station95.nc')\n",
    "ar_yesno6=ds6['ar_yesno'].values.tolist()\n",
    "ivt_yesno6=ds6['ivt_yesno'].values.tolist()\n",
    "tc_yesno6=ds6['tc_yesno'].values.tolist()\n",
    "other_yesno6=ds6['other_yesno'].values.tolist()\n",
    "tc_linked_ar_yesno6=ds6['tc_linked_ar_yesno'].values.tolist()\n",
    "tc_linked_ivt_yesno6=ds6['tc_linked_ivt_yesno'].values.tolist()\n",
    "tc_remnant_linked_ivt_yesno6=ds6['ivt_tc_remnants_yesno'].values.tolist()\n",
    "tc_remnant_ar_combo_yesno6=ds6['ar_tc_remnant_combo_yesno'].values.tolist()\n",
    "tc_remnant_linked_ar_yesno6=ds6['tc_remnant_linked_ar_yesno'].values.tolist()\n",
    "tc_remnants_yesno6=ds6['tc_remnants_yesno'].values.tolist()\n",
    "tc_ar_combo_yesno6=ds6['tc_ar_combo_yesno'].values.tolist()\n",
    "\n",
    "ar_sum_1=sum(ar_yesno1)+sum(tc_linked_ar_yesno1)+sum(tc_remnant_linked_ar_yesno1)#+sum(tc_ar_combo_yesno1)+sum(tc_remnant_ar_combo_yesno1)\n",
    "ar_sum_2=sum(ar_yesno2)+sum(tc_linked_ar_yesno2)+sum(tc_remnant_linked_ar_yesno2)#+sum(tc_ar_combo_yesno2)+sum(tc_remnant_ar_combo_yesno2)\n",
    "ar_sum_3=sum(ar_yesno3)+sum(tc_linked_ar_yesno3)+sum(tc_remnant_linked_ar_yesno3)#+sum(tc_ar_combo_yesno3)+sum(tc_remnant_ar_combo_yesno3)\n",
    "ar_sum_4=sum(ar_yesno4)+sum(tc_linked_ar_yesno4)+sum(tc_remnant_linked_ar_yesno4)#+sum(tc_ar_combo_yesno4)+sum(tc_remnant_ar_combo_yesno4)\n",
    "ar_sum_5=sum(ar_yesno5)+sum(tc_linked_ar_yesno5)+sum(tc_remnant_linked_ar_yesno5)#+sum(tc_ar_combo_yesno5)+sum(tc_remnant_ar_combo_yesno5)\n",
    "ar_sum_6=sum(ar_yesno6)+sum(tc_linked_ar_yesno6)+sum(tc_remnant_linked_ar_yesno6)#+sum(tc_ar_combo_yesno6)+sum(tc_remnant_ar_combo_yesno6)\n",
    "\n",
    "\n",
    "ar_all_1=[x+y+z for x,y,z,w,q in zip(ar_yesno1,tc_linked_ar_yesno1,tc_remnant_linked_ar_yesno1,tc_ar_combo_yesno1,tc_remnant_ar_combo_yesno1)]\n",
    "print(ar_all_1)\n",
    "print(years)\n",
    "ar_all_2=[x+y+z for x,y,z,w,q in zip(ar_yesno2,tc_linked_ar_yesno2,tc_remnant_linked_ar_yesno2,tc_ar_combo_yesno2,tc_remnant_ar_combo_yesno2)]\n",
    "ar_all_3=[x+y+z for x,y,z,w,q in zip(ar_yesno3,tc_linked_ar_yesno3,tc_remnant_linked_ar_yesno3,tc_ar_combo_yesno3,tc_remnant_ar_combo_yesno3)]\n",
    "ar_all_4=[x+y+z for x,y,z,w,q in zip(ar_yesno4,tc_linked_ar_yesno4,tc_remnant_linked_ar_yesno4,tc_ar_combo_yesno4,tc_remnant_ar_combo_yesno4)]\n",
    "ar_all_5=[x+y+z for x,y,z,w,q in zip(ar_yesno5,tc_linked_ar_yesno5,tc_remnant_linked_ar_yesno5,tc_ar_combo_yesno5,tc_remnant_ar_combo_yesno5)]\n",
    "ar_all_6=[x+y+z for x,y,z,w,q in zip(ar_yesno6,tc_linked_ar_yesno6,tc_remnant_linked_ar_yesno6,tc_ar_combo_yesno6,tc_remnant_ar_combo_yesno6)]\n",
    "\n",
    "zipped_ar1_obs=list(zip(years,ar_all_1,mean_obs_list))\n",
    "zipped_ar2_obs=list(zip(years,ar_all_2,mean_obs_list))\n",
    "zipped_ar3_obs=list(zip(years,ar_all_3,mean_obs_list))\n",
    "zipped_ar4_obs=list(zip(years,ar_all_4,mean_obs_list))\n",
    "zipped_ar5_obs=list(zip(years,ar_all_5,mean_obs_list))\n",
    "zipped_ar6_obs=list(zip(years,ar_all_6,mean_obs_list))\n",
    "\n",
    "#Now want to get fraction of total EP day rainfall that comes from ARs\n",
    "select_ar1_obs=[x[2] for x in zipped_ar1_obs if x[1]==1]\n",
    "select_ar2_obs=[x[2] for x in zipped_ar2_obs if x[1]==1]\n",
    "select_ar3_obs=[x[2] for x in zipped_ar3_obs if x[1]==1]\n",
    "select_ar4_obs=[x[2] for x in zipped_ar4_obs if x[1]==1]\n",
    "select_ar5_obs=[x[2] for x in zipped_ar5_obs if x[1]==1]\n",
    "select_ar6_obs=[x[2] for x in zipped_ar6_obs if x[1]==1]\n",
    "\n",
    "ratio_ar1_obs=sum(select_ar1_obs)/sum(mean_obs_list)*100.\n",
    "ratio_ar2_obs=sum(select_ar2_obs)/sum(mean_obs_list)*100.\n",
    "ratio_ar3_obs=sum(select_ar3_obs)/sum(mean_obs_list)*100.\n",
    "ratio_ar4_obs=sum(select_ar4_obs)/sum(mean_obs_list)*100.\n",
    "ratio_ar5_obs=sum(select_ar5_obs)/sum(mean_obs_list)*100.\n",
    "ratio_ar6_obs=sum(select_ar6_obs)/sum(mean_obs_list)*100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric 1: # of days of AR precipitation\n",
    "print(ar_sum_1)\n",
    "print(ar_sum_2)\n",
    "print(sum(select_ar1_obs))\n",
    "print(sum(select_ar2_obs))\n",
    "print(len(ar_yesno1))\n",
    "print([x-y for x,y in zip(ar_all_1,ar_all_2)])\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "ax=plt.subplot(1,1,1)\n",
    "metrics=['90%','92.5%','95%','Const 95%','97.5%','99%']\n",
    "ratios=[ratio_ar1_obs,ratio_ar2_obs,ratio_ar3_obs,ratio_ar4_obs,ratio_ar5_obs,ratio_ar6_obs]\n",
    "\n",
    "ar_sums=[ar_sum_1,ar_sum_2,ar_sum_3,ar_sum_4,ar_sum_5,ar_sum_6]\n",
    "ar_sums=[float(x)/float(len(ar_yesno1))*100. for x in ar_sums]\n",
    "#colors=['c','deepskyblue','dodgerblue','blue','blueviolet','k']\n",
    "#ax.plot(metrics,ar_sums,color='b')\n",
    "ax.bar(metrics,ar_sums,color='limegreen',alpha=0.5,label='Percentage of EP Days')\n",
    "ax.tick_params(labelsize=19)\n",
    "ax.set_title('IVT Threshold Testing: AR-dominant EP Days',fontsize=24)\n",
    "ax.set_ylabel('%',labelpad=15,fontsize=19)\n",
    "#plt.xticks(rotation=75)\n",
    "ax.set_xlabel('IVT percentile threshold',fontsize=19,labelpad=15)\n",
    "\n",
    "for i in range(len(ar_sums)):\n",
    "    plt.axvline(x=metrics[i],ymax=ratios[i]/100.,color='k')\n",
    "    if i==0:\n",
    "        ax.plot(metrics[i],ratios[i],color='k',marker='o',mew=3.0,markerfacecolor='w',markersize=15,label='Percentage of EP day precip')\n",
    "    else:\n",
    "        ax.plot(metrics[i],ratios[i],color='k',marker='o',mew=3.0,markerfacecolor='w',markersize=15)\n",
    "\n",
    "ax.set_ylim(0,100)\n",
    "plt.grid(True,color='grey',linestyle='--')\n",
    "plt.legend(loc='upper left',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'NEUSA_IVT_testing_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:#NEUSA\n",
    "    time=ds1.time\n",
    "    dates_pd=pd.DatetimeIndex(time.values)\n",
    "    years=[x.year for x in dates_pd]\n",
    "    print(years)\n",
    "if 1==0:#Taiwan\n",
    "    dates_pd=pd.DatetimeIndex(dates.values)\n",
    "    years=[x.year for x in dates_pd]\n",
    "    print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric 2: trends in AR day frequency (do % for axis)\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "ax=plt.subplot(1,1,1)\n",
    "metrics=['90%','92.5%','95%','Const 95%','97.5%','99%']\n",
    "\n",
    "\n",
    "ar1_annual_list=[]\n",
    "ar1_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar1_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar1_annual_list.append(num_year)\n",
    "    ar1_precip_list.append(precip_sum)\n",
    "    \n",
    "ar2_annual_list=[]\n",
    "ar2_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar2_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar2_annual_list.append(num_year)\n",
    "    ar2_precip_list.append(precip_sum)\n",
    "    \n",
    "ar3_annual_list=[]\n",
    "ar3_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar3_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar3_annual_list.append(num_year)\n",
    "    ar3_precip_list.append(precip_sum)\n",
    "    \n",
    "ar4_annual_list=[]\n",
    "ar4_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar4_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar4_annual_list.append(num_year)\n",
    "    ar4_precip_list.append(precip_sum)\n",
    "    \n",
    "ar5_annual_list=[]\n",
    "ar5_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar5_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar5_annual_list.append(num_year)\n",
    "    ar5_precip_list.append(precip_sum)\n",
    "    \n",
    "ar6_annual_list=[]\n",
    "ar6_precip_list=[]\n",
    "for i in range(len(np.arange(1979,2020,1))):\n",
    "    year=1979+i\n",
    "    select_year=[x for x in zipped_ar6_obs if x[0]==year and x[1]==1]\n",
    "    num_year=len(select_year)\n",
    "    precip_year=[x[2] for x in select_year]\n",
    "    precip_sum=sum(precip_year)\n",
    "    ar6_annual_list.append(num_year)\n",
    "    ar6_precip_list.append(precip_sum)\n",
    "\n",
    "print(ar1_annual_list)\n",
    "print(ar2_annual_list)\n",
    "print(ar3_annual_list)\n",
    "print(ar4_annual_list)\n",
    "print(ar5_annual_list)\n",
    "print(ar6_annual_list)\n",
    "\n",
    "ar1_mean_freq=float(sum(ar1_annual_list))/float(len(ar1_annual_list))\n",
    "ar2_mean_freq=float(sum(ar2_annual_list))/float(len(ar2_annual_list))\n",
    "ar3_mean_freq=float(sum(ar3_annual_list))/float(len(ar3_annual_list))\n",
    "ar4_mean_freq=float(sum(ar4_annual_list))/float(len(ar4_annual_list))\n",
    "ar5_mean_freq=float(sum(ar5_annual_list))/float(len(ar5_annual_list))\n",
    "ar6_mean_freq=float(sum(ar6_annual_list))/float(len(ar6_annual_list))\n",
    "\n",
    "ar1_mean_precip=float(sum(ar1_precip_list))/float(len(ar1_precip_list))\n",
    "ar2_mean_precip=float(sum(ar2_precip_list))/float(len(ar2_precip_list))\n",
    "ar3_mean_precip=float(sum(ar3_precip_list))/float(len(ar3_precip_list))\n",
    "ar4_mean_precip=float(sum(ar4_precip_list))/float(len(ar4_precip_list))\n",
    "ar5_mean_precip=float(sum(ar5_precip_list))/float(len(ar5_precip_list))\n",
    "ar6_mean_precip=float(sum(ar6_precip_list))/float(len(ar6_precip_list))\n",
    "\n",
    "yrs_neusa=np.arange(1979,2020,1)\n",
    "#reg_1=st.theilslopes(ar1_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_1=st.linregress(yrs_neusa,ar1_annual_list)\n",
    "slope_1=reg_1[0]/ar1_mean_freq*100.\n",
    "p_value_1=reg_1[3]\n",
    "#lo_slope_1=reg_1[2]\n",
    "#hi_slope_1=reg_1[3]\n",
    "\n",
    "reg_2=st.theilslopes(ar2_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_2=st.linregress(yrs_neusa,ar2_annual_list)\n",
    "slope_2=reg_2[0]/ar2_mean_freq*100.\n",
    "p_value_2=reg_2[3]\n",
    "#lo_slope_2=reg_2[2]\n",
    "#hi_slope_2=reg_2[3]\n",
    "\n",
    "reg_3=st.theilslopes(ar3_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_3=st.linregress(yrs_neusa,ar3_annual_list)\n",
    "slope_3=reg_3[0]/ar3_mean_freq*100.\n",
    "p_value_3=reg_3[3]\n",
    "#lo_slope_3=reg_3[2]\n",
    "#hi_slope_3=reg_3[3]\n",
    "\n",
    "reg_4=st.theilslopes(ar4_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_4=st.linregress(yrs_neusa,ar4_annual_list)\n",
    "slope_4=reg_4[0]/ar4_mean_freq*100.\n",
    "p_value_4=reg_4[3]\n",
    "#lo_slope_4=reg_4[2]\n",
    "#hi_slope_4=reg_4[3]\n",
    "\n",
    "reg_5=st.theilslopes(ar5_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_5=st.linregress(yrs_neusa,ar5_annual_list)\n",
    "slope_5=reg_5[0]/ar5_mean_freq*100.\n",
    "p_value_5=reg_5[3]\n",
    "#lo_slope_5=reg_5[2]\n",
    "#hi_slope_5=reg_5[3]\n",
    "\n",
    "reg_6=st.theilslopes(ar6_annual_list,yrs_neusa,alpha=0.95)\n",
    "reg_6=st.linregress(yrs_neusa,ar6_annual_list)\n",
    "slope_6=reg_6[0]/ar6_mean_freq*100.\n",
    "p_value_6=reg_6[3]\n",
    "#lo_slope_6=reg_6[2]\n",
    "#hi_slope_6=reg_6[3]\n",
    "\n",
    "reg_1a=st.linregress(yrs_neusa,ar1_precip_list)\n",
    "slope_1a=reg_1a[0]/ar1_mean_precip*100.\n",
    "p_value_1a=reg_1a[3]\n",
    "\n",
    "reg_2a=st.linregress(yrs_neusa,ar2_precip_list)\n",
    "slope_2a=reg_2a[0]/ar2_mean_precip*100.\n",
    "p_value_2a=reg_2a[3]\n",
    "\n",
    "reg_3a=st.linregress(yrs_neusa,ar3_precip_list)\n",
    "slope_3a=reg_3a[0]/ar3_mean_precip*100.\n",
    "p_value_3a=reg_3a[3]\n",
    "\n",
    "reg_4a=st.linregress(yrs_neusa,ar4_precip_list)\n",
    "slope_4a=reg_4a[0]/ar4_mean_precip*100.\n",
    "p_value_4a=reg_4a[3]\n",
    "\n",
    "reg_5a=st.linregress(yrs_neusa,ar5_precip_list)\n",
    "slope_5a=reg_5a[0]/ar5_mean_precip*100.\n",
    "p_value_5a=reg_5a[3]\n",
    "\n",
    "reg_6a=st.linregress(yrs_neusa,ar6_precip_list)\n",
    "slope_6a=reg_6a[0]/ar6_mean_precip*100.\n",
    "p_value_6a=reg_6a[3]\n",
    "\n",
    "slopes=[slope_1,slope_2,slope_3,slope_4,slope_5,slope_6]\n",
    "p_values=[p_value_1,p_value_2,p_value_3,p_value_4,p_value_5,p_value_6]\n",
    "\n",
    "slopes_precip=[slope_1a,slope_2a,slope_3a,slope_4a,slope_5a,slope_6a]\n",
    "p_values_precip=[p_value_1a,p_value_2a,p_value_3a,p_value_4a,p_value_5a,p_value_6a]\n",
    "print(slopes)\n",
    "print(p_values)\n",
    "print(slopes_precip)\n",
    "print(p_values_precip)\n",
    "#lower_bounds=[lo_slope_1,lo_slope_2,lo_slope_3,lo_slope_4,lo_slope_5,lo_slope_6]\n",
    "#upper_bounds=[hi_slope_1,hi_slope_2,hi_slope_3,hi_slope_4,hi_slope_5,hi_slope_6]\n",
    "#sys.exit()\n",
    "colors=['c','deepskyblue','dodgerblue','blue','blueviolet','k']\n",
    "#ax.plot(metrics,ar_sums,color='b')\n",
    "ax.bar(metrics,slopes,color='limegreen',alpha=0.5,label='AR-associated EP day frequency')\n",
    "for i in range(len(slopes)):\n",
    "    #plt.axvline(x=metrics[i],ymin=slopes_precip[i],ymax=0,color='k')\n",
    "    ax.plot([metrics[i],metrics[i]],[slopes_precip[i],0],color='k',linewidth=1.0)\n",
    "    if i==0:\n",
    "        ax.plot(metrics[i],slopes_precip[i],color='k',marker='o',mew=3,markerfacecolor='w',markersize=15,label='AR-associated EP day precip')\n",
    "    else:\n",
    "        ax.plot(metrics[i],slopes_precip[i],color='k',marker='o',mew=3,markerfacecolor='w',markersize=15)\n",
    "    ax.text(metrics[i],slopes_precip[i]+0.35*np.sign(slopes_precip[i]),'p='+str(round(p_values_precip[i],3)),ha='center',fontsize=15)\n",
    "    #ax.plot(metrics[i],slopes[i],color=colors[i],marker='o',mew=3,markerfacecolor='None',markersize=15)\n",
    "    #ax.plot(metrics[i],lower_bounds[i],color=colors[i],marker='_',markersize=15)\n",
    "    #ax.plot(metrics[i],upper_bounds[i],color=colors[i],marker='_',markersize=15)\n",
    "    #ax.plot([metrics[i],metrics[i]],[lower_bounds[i],slopes[i]-0.01],color=colors[i],linestyle='solid',linewidth=0.5)\n",
    "    #ax.plot([metrics[i],metrics[i]],[slopes[i]+0.01,upper_bounds[i]],color=colors[i],linestyle='solid',linewidth=0.5)\n",
    "print(ar1_annual_list)\n",
    "print(ar2_annual_list)\n",
    "print(ar3_annual_list)\n",
    "ax.tick_params(labelsize=19)\n",
    "ax.set_title('Trends in AR-dominant EP Days',fontsize=24)\n",
    "ax.set_ylabel('Trend (%/year)',labelpad=15,fontsize=19)\n",
    "plt.grid(True,color='grey',linestyle='--')\n",
    "ax.set_ylim(0,6.5)\n",
    "#ax.set_ylim(-4,4)\n",
    "ax.set_xlabel('IVT percentile threshold',fontsize=19,labelpad=15)\n",
    "plt.legend(loc='upper left',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'NEUSA_IVT_testing_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(14,14))\n",
    "ax=plt.subplot(1,1,1)\n",
    "\n",
    "running_mean_1=[]\n",
    "running_mean_2=[]\n",
    "running_mean_3=[]\n",
    "running_mean_4=[]\n",
    "running_mean_5=[]\n",
    "running_mean_6=[]\n",
    "for i in range(len(yrs_neusa)-10):\n",
    "    segment_1=ar1_annual_list[i:i+10]\n",
    "    mean_1=float(sum(segment_1))/float(len(segment_1))\n",
    "    running_mean_1.append(mean_1)\n",
    "    \n",
    "    segment_2=ar2_annual_list[i:i+10]\n",
    "    mean_2=float(sum(segment_2))/float(len(segment_2))\n",
    "    running_mean_2.append(mean_2)\n",
    "    \n",
    "    segment_3=ar3_annual_list[i:i+10]\n",
    "    mean_3=float(sum(segment_3))/float(len(segment_3))\n",
    "    running_mean_3.append(mean_3)\n",
    "    \n",
    "    segment_4=ar4_annual_list[i:i+10]\n",
    "    mean_4=float(sum(segment_4))/float(len(segment_4))\n",
    "    running_mean_4.append(mean_4)\n",
    "    \n",
    "    segment_5=ar5_annual_list[i:i+10]\n",
    "    mean_5=float(sum(segment_5))/float(len(segment_5))\n",
    "    running_mean_5.append(mean_5)\n",
    "    \n",
    "    segment_6=ar6_annual_list[i:i+10]\n",
    "    mean_6=float(sum(segment_6))/float(len(segment_6))\n",
    "    running_mean_6.append(mean_6)\n",
    "    \n",
    "ax.plot(yrs_neusa,ar1_annual_list,linewidth=0.5,color='orange',label='90th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_1,linewidth=3.5,color='orange')\n",
    "ax.plot(yrs_neusa,ar2_annual_list,linewidth=0.5,color='darkorange',label='92.5th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_2,linewidth=3.5,color='darkorange')\n",
    "ax.plot(yrs_neusa,ar3_annual_list,linewidth=0.5,color='r',label='95th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_3,linewidth=3.5,color='r')\n",
    "ax.plot(yrs_neusa,ar4_annual_list,linewidth=0.5,color='darkred',label='Constant 95th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_4,linewidth=3.5,color='darkred')\n",
    "ax.plot(yrs_neusa,ar5_annual_list,linewidth=0.5,color='m',label='97.5th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_5,linewidth=3.5,color='m')\n",
    "ax.plot(yrs_neusa,ar6_annual_list,linewidth=0.5,color='k',label='99th percentile')\n",
    "ax.plot(yrs_neusa[5:-5],running_mean_6,linewidth=3.5,color='k')\n",
    "ax.tick_params(labelsize=19)\n",
    "ax.set_xlabel('Year',fontsize=19,labelpad=15)\n",
    "ax.set_ylabel('Number of Days',fontsize=19)\n",
    "ax.set_title('AR-associated EP Day Frequency',fontsize=24)\n",
    "ax.set_ylim(0,6.2)\n",
    "plt.legend(loc='upper left',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(dir+'Taiwan_IVT_testing_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-programmer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 June 2020 Environment",
   "language": "python",
   "name": "jun20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
